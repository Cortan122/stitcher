{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv-ohZNbMWAQ"
      },
      "source": [
        "# Специальный Image Stitching для скриншотов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EGKk3YuMI2E",
        "outputId": "547ec0fb-f16d-4fbe-81eb-2b5de316468b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'stitcher' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Cortan122/stitcher\n",
        "!cp stitcher/* -r ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsD48eaZNnj2"
      },
      "source": [
        "## Сначала пробуем обычный cv2.Stitcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "EpDKv2FqNnUZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imutils\n",
        "\n",
        "def basic_stitch(paths, rotate=False, scans_mode=False):\n",
        "  imgs = [cv2.imread(path) for path in paths]\n",
        "\n",
        "  if rotate:\n",
        "    for i, img in enumerate(imgs):\n",
        "      imgs[i] = imutils.rotate_bound(img, 90)\n",
        "\n",
        "  if scans_mode:\n",
        "    stitcher = cv2.Stitcher.create(cv2.Stitcher_SCANS)\n",
        "  else:\n",
        "    stitcher = cv2.Stitcher.create()\n",
        "  stitcher.setWaveCorrection(False)\n",
        "  error_code, output = stitcher.stitch(imgs)\n",
        "\n",
        "  if error_code == cv2.STITCHER_OK:\n",
        "    if rotate:\n",
        "      output = imutils.rotate_bound(output, -90)\n",
        "    return output\n",
        "  else:\n",
        "    raise \"stitcher fail!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5wQNpusPYYN"
      },
      "source": [
        "### Настоящие панорамы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "GzwHdnHKNr1u",
        "outputId": "97d107a4-ac92-4e50-ddd7-082049559e4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/Cortan122/stitcher/master/test%20cases/carmel_1.png\" width=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/Cortan122/stitcher/master/test%20cases/carmel_2.png\" width=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/Cortan122/stitcher/master/test%20cases/carmel_3.png\" width=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/Cortan122/stitcher/master/test%20cases/carmel_4.png\" width=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "GIT_REPO_RAW = \"https://raw.githubusercontent.com/Cortan122/stitcher/master/test%20cases/\"\n",
        "def display_images(url, number, base=1, width=200):\n",
        "  urls = [url.format(i+base) for i in range(number)]\n",
        "  imgs = [Image(url=s, width=200) for s in urls]\n",
        "  display(*imgs)\n",
        "\n",
        "display_images(GIT_REPO_RAW+\"carmel_{}.png\", 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "VGzCHBH9QJew",
        "outputId": "d3c77bef-f21d-4433-d05b-9a068b37c5fa"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = basic_stitch([f\"test cases/carmel_{i}.png\" for i in range(1, 5)])\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty7HlHjLTEO2"
      },
      "source": [
        "Работает идеально, как и можно было ожидать..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Ncv47oTI6w"
      },
      "source": [
        "### Аниме"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9iqiEmuPSJ2L",
        "outputId": "3909adec-6d52-44b2-84b8-9745ee6f8d08"
      },
      "outputs": [],
      "source": [
        "display_images(GIT_REPO_RAW+\"animepan_{}.jpg\", 5)\n",
        "cv2_imshow(basic_stitch([f\"test cases/animepan_{i}.jpg\" for i in range(1, 6)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGXYnXQYovt"
      },
      "source": [
        "### Чат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ao0uERN8Teyt",
        "outputId": "4acc8ca3-eca9-434e-eefb-7a4a4e894467"
      },
      "outputs": [],
      "source": [
        "display_images(GIT_REPO_RAW+\"cropchat_{}.jpg\", 3)\n",
        "paths = [f\"test cases/cropchat_{i}.jpg\" for i in range(1, 4)]\n",
        "cv2_imshow(basic_stitch(paths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfD1HlvY3VH"
      },
      "source": [
        "Здесь нас спасает `stitcher.setWaveCorrection(False)`. Без него вся программа бы упала с аллокацией на несколько гигабайтов, и её бы приходилось спасать ужасным костылём с поворотом всех картинок на 90 градусов и потом обратно... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8KY8vdmd9Hn"
      },
      "source": [
        "### Файлы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xKWkKwKSZDlH",
        "outputId": "acad22a5-78dd-4037-b82f-a4fcd549080e"
      },
      "outputs": [],
      "source": [
        "display_images(GIT_REPO_RAW+\"files_{}.png\", 9)\n",
        "paths = [f\"test cases/files_{i}.png\" for i in range(1, 10)]\n",
        "cv2_imshow(basic_stitch(paths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_1Og9q7d_fe"
      },
      "source": [
        "Сдесь получилось склеить только две картники, а куда все остальные делись я не знаю 0_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4QstVURjn1b"
      },
      "source": [
        "### Clip art (убийственный тест)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dwW9Bh0tjuE4",
        "outputId": "7d2e4b06-d022-4012-fff8-3f36099139ea"
      },
      "outputs": [],
      "source": [
        "display_images(GIT_REPO_RAW+\"undraw_{}.png\", 9, 0)\n",
        "paths = [f\"test cases/undraw_{i}.png\" for i in range(9)]\n",
        "cv2_imshow(basic_stitch(paths, scans_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP8SZuF6kNwd"
      },
      "source": [
        "Всё соовсем поплыло, потому что он не смог найти достаточно фич. Эта картинка слишком гладкая... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDyNF5QeOVl"
      },
      "source": [
        "## Совпадение фич"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OEeLV-GWdxZh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def fast_detectAndCompute(img):\n",
        "  # Initiate FAST detector\n",
        "  star = cv2.xfeatures2d.StarDetector_create()\n",
        "  # Initiate BRIEF extractor\n",
        "  brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
        "  # find the keypoints with STAR\n",
        "  kp = star.detect(img, None)\n",
        "  # compute the descriptors with BRIEF\n",
        "  return brief.compute(img, kp)\n",
        "\n",
        "def overlay_images(img1, img2, delta):\n",
        "  h = max(img1.shape[0], img2.shape[0] + delta[0])\n",
        "  w = max(img1.shape[1], img2.shape[1] + delta[1])\n",
        "  res = np.zeros((h,w,3), dtype='uint8')\n",
        "  res[:img1.shape[0],:img1.shape[1],:] = img1\n",
        "  res[delta[0]:img2.shape[0] + delta[0],delta[1]:img2.shape[1] + delta[1],:] = img2\n",
        "  return res\n",
        "\n",
        "def feature_matcher_img(path1, path2):\n",
        "  img1 = cv2.imread(path1, cv2.IMREAD_GRAYSCALE)  # queryImage\n",
        "  img2 = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)  # trainImage\n",
        "\n",
        "  # find the keypoints and descriptors with SIFT\n",
        "  kp1, des1 = fast_detectAndCompute(img1)\n",
        "  kp2, des2 = fast_detectAndCompute(img2)\n",
        "\n",
        "  # BFMatcher with default params\n",
        "  bf = cv2.BFMatcher()\n",
        "  matches = bf.knnMatch(des1, des2, k=2)\n",
        "\n",
        "  # Apply ratio test\n",
        "  good = []\n",
        "  for m, n in matches:\n",
        "    if m.distance < 0.75*n.distance:\n",
        "      if kp1[m.queryIdx].pt != kp2[m.trainIdx].pt:\n",
        "        good.append([m])\n",
        "        \n",
        "  cv2_imshow(cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wHbEjcGgAoO"
      },
      "source": [
        "### Панорама"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "f5Kjk3qPf_ei",
        "outputId": "bf0404ba-a18a-4493-fc63-aaab9a0dc52d"
      },
      "outputs": [],
      "source": [
        "feature_matcher_img(\"test cases/carmel_4.png\", \"test cases/carmel_3.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah8lnf9hgZ53"
      },
      "source": [
        "### Аниме"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "thZ7uoCYgRmY",
        "outputId": "c7d2eb98-450f-4756-dfaf-7795aa542bd3"
      },
      "outputs": [],
      "source": [
        "feature_matcher_img(\"test cases/animepan_3.jpg\", \"test cases/animepan_4.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX54QO8agqFj"
      },
      "source": [
        "### Текст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9V1x4D0Sge8T",
        "outputId": "1e252de1-a684-49ff-e221-fae28838d5f3"
      },
      "outputs": [],
      "source": [
        "feature_matcher_img(\"test cases/chat_2.jpg\", \"test cases/chat_3.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkh2RJcDg38F"
      },
      "source": [
        "## Пробуем свой метод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TI7YjCjiD2x"
      },
      "source": [
        "### Очень много кода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "oR9gHIoIg9Ke"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "from collections import Counter\n",
        "\n",
        "USE_SIFT = True\n",
        "ALIGNMENT_SCORE_THRESHOLD = 0.015\n",
        "TOP_BOTTOM_THRESHOLD = 10\n",
        "GREEDY_HEADER = False\n",
        "HORIZONTAL_MARGIN = 0\n",
        "REFERENCE_HEADER_IMAGE = 0\n",
        "\n",
        "\n",
        "def diff_images(img1, img2):\n",
        "  h = min(img1.shape[0], img2.shape[0])\n",
        "  w = min(img1.shape[1], img2.shape[1])\n",
        "\n",
        "  diff = cv2.absdiff(img1[:h,:w], img2[:h,:w])\n",
        "  mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "  boolmask = mask < TOP_BOTTOM_THRESHOLD  # type: ignore\n",
        "\n",
        "  row_threshold = w - 20\n",
        "  row_sum = np.sum(boolmask, axis=1)\n",
        "  row_mask = row_sum < row_threshold\n",
        "  index_array = np.where(row_mask)[0]\n",
        "\n",
        "  return index_array[0], index_array[-1]\n",
        "\n",
        "\n",
        "def find_features(imgs):\n",
        "  gray_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in imgs]\n",
        "  if USE_SIFT:\n",
        "    sift = cv2.SIFT_create()\n",
        "    return [sift.detectAndCompute(img, None) for img in gray_imgs]\n",
        "  else:\n",
        "    star = cv2.xfeatures2d.StarDetector_create()\n",
        "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
        "    return [brief.compute(img, star.detect(img, None)) for img in gray_imgs]\n",
        "\n",
        "\n",
        "def crop_images(imgs):\n",
        "  if REFERENCE_HEADER_IMAGE == -1:\n",
        "    return imgs, imgs[0][:0,:0,:], imgs[0][:0,:0,:]\n",
        "\n",
        "  j = min(REFERENCE_HEADER_IMAGE, len(imgs)-1)\n",
        "  bounds = [diff_images(imgs[j], imgs[i]) for i in range(len(imgs)) if i != j]\n",
        "  if GREEDY_HEADER:\n",
        "    min_bound = max(bounds, key=lambda x: x[0])[0]\n",
        "    max_bound = min(bounds, key=lambda x: x[1])[1]\n",
        "  else:\n",
        "    min_bound = min(bounds, key=lambda x: x[0])[0]\n",
        "    max_bound = max(bounds, key=lambda x: x[1])[1]\n",
        "\n",
        "  mslice = slice(HORIZONTAL_MARGIN, -HORIZONTAL_MARGIN)\n",
        "  if HORIZONTAL_MARGIN == 0:\n",
        "    mslice = slice(None, None)\n",
        "  cropped_imgs = [img[min_bound:max_bound,mslice,:] for img in imgs]\n",
        "  top = imgs[0][:min_bound,mslice,:]\n",
        "  bottom = imgs[-1][max_bound:,mslice,:]\n",
        "  return cropped_imgs, top, bottom\n",
        "\n",
        "\n",
        "def match_features(feat1, feat2):\n",
        "  kp1, des1 = feat1\n",
        "  kp2, des2 = feat2\n",
        "\n",
        "  # BFMatcher with default params\n",
        "  bf = cv2.BFMatcher()\n",
        "  try:\n",
        "    matches = bf.knnMatch(des1, des2, k=2)\n",
        "  except cv2.error as e:\n",
        "    print(e)\n",
        "    return []\n",
        "\n",
        "  # Apply ratio test\n",
        "  deltas = []\n",
        "  for m, n in matches:\n",
        "    if m.distance < 0.75*n.distance:\n",
        "      if kp1[m.queryIdx].pt != kp2[m.trainIdx].pt:\n",
        "        pt1, pt2 = kp1[m.queryIdx].pt, kp2[m.trainIdx].pt\n",
        "        deltas.append((int(pt1[0] - pt2[0]), int(pt1[1] - pt2[1])))\n",
        "\n",
        "  return [(dx,dy) for (dx,dy), c in Counter(deltas).most_common(10) if c > 1]\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/a/25068722\n",
        "class Rectangle:\n",
        "  def __and__(self, other: \"Rectangle\"):\n",
        "    a, b = self, other\n",
        "    x1 = max(min(a.x1, a.x2), min(b.x1, b.x2))\n",
        "    y1 = max(min(a.y1, a.y2), min(b.y1, b.y2))\n",
        "    x2 = min(max(a.x1, a.x2), max(b.x1, b.x2))\n",
        "    y2 = min(max(a.y1, a.y2), max(b.y1, b.y2))\n",
        "    return Rectangle(x1, y1, x2, y2)\n",
        "\n",
        "  def __or__(self, other: \"Rectangle\"):\n",
        "    a, b = self, other\n",
        "    x1 = min(a.x1, a.x2, b.x1, b.x2)\n",
        "    y1 = min(a.y1, a.y2, b.y1, b.y2)\n",
        "    x2 = max(a.x1, a.x2, b.x1, b.x2)\n",
        "    y2 = max(a.y1, a.y2, b.y1, b.y2)\n",
        "    return Rectangle(x1, y1, x2, y2)\n",
        "\n",
        "  def __init__(self, x1, y1, x2, y2):\n",
        "    if x1>x2 or y1>y2:\n",
        "      raise ValueError(\"Coordinates are invalid\")\n",
        "    self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n",
        "\n",
        "  def __add__(self, point):\n",
        "    dx, dy = point\n",
        "    x1 = self.x1 + dx\n",
        "    x2 = self.x2 + dx\n",
        "    y1 = self.y1 + dy\n",
        "    y2 = self.y2 + dy\n",
        "    return Rectangle(x1, y1, x2, y2)\n",
        "\n",
        "  def __sub__(self, point):\n",
        "    dx, dy = point\n",
        "    x1 = self.x1 - dx\n",
        "    x2 = self.x2 - dx\n",
        "    y1 = self.y1 - dy\n",
        "    y2 = self.y2 - dy\n",
        "    return Rectangle(x1, y1, x2, y2)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Rectangle({self.x1}, {self.y1}, {self.x2}, {self.y2})\"\n",
        "\n",
        "  @staticmethod\n",
        "  def from_xywh(x, y, w, h):\n",
        "    x1, y1, x2, y2 = x, y, x+w, y+h\n",
        "    return Rectangle(min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2))\n",
        "\n",
        "  @staticmethod\n",
        "  def from_img(img):\n",
        "    return Rectangle.from_xywh(0, 0, img.shape[0], img.shape[1])\n",
        "\n",
        "  @property\n",
        "  def w(self):\n",
        "    return self.x2 - self.x1\n",
        "\n",
        "  @property\n",
        "  def h(self):\n",
        "    return self.y2 - self.y1\n",
        "\n",
        "\n",
        "def show_boolmask(mask, block):\n",
        "  canvas = np.zeros_like(block, np.uint8)\n",
        "  canvas[:,:,0] = 0xff\n",
        "  canvas[:,:,2] = 0xff\n",
        "  canvas[mask] = block[mask]\n",
        "  cv2.imshow(\"canvas\", canvas)\n",
        "\n",
        "\n",
        "def overlay_score(img1, img2, delta: tuple[int, int]):\n",
        "  r1 = Rectangle.from_img(img1)\n",
        "  r2 = Rectangle.from_img(img2) + delta\n",
        "  r3 = r1 & r2\n",
        "  r4 = r3 - delta\n",
        "\n",
        "  block1 = img1[r3.x1:r3.x2,r3.y1:r3.y2,:]\n",
        "  block2 = img2[r4.x1:r4.x2,r4.y1:r4.y2,:]\n",
        "  diff = cv2.absdiff(block1, block2)\n",
        "  mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "  boolmask = mask < 30  # type: ignore\n",
        "  # show_boolmask(boolmask, block1)\n",
        "  return np.sum(~boolmask) / boolmask.size\n",
        "\n",
        "\n",
        "def overlay_images(imgs, deltas: list[tuple[int, int]]):\n",
        "  rects = [Rectangle.from_img(img) + delta for img, delta in zip(imgs, deltas)]\n",
        "  r3 = reduce(lambda x,y: x|y, rects, rects[0])\n",
        "  rects2 = [rect - (r3.x1, r3.y1) for rect in rects]\n",
        "\n",
        "  res = np.zeros((r3.w,r3.h,3), dtype='uint8')\n",
        "  for rect, img in zip(rects2, imgs):\n",
        "    res[rect.x1:rect.x2,rect.y1:rect.y2,:] = img\n",
        "  return res\n",
        "\n",
        "\n",
        "def find_top_bottom(imgs, deltas: list[tuple[int, int]]):\n",
        "  rects = [Rectangle.from_img(img) + delta for img, delta in zip(imgs, deltas)]\n",
        "  r3 = reduce(lambda x,y: x|y, rects, rects[0])\n",
        "  return r3.x1, r3.x2\n",
        "\n",
        "\n",
        "def main(paths, outpath=None):\n",
        "  imgs = [cv2.imread(path) for path in paths]\n",
        "  cropped_imgs, top, bottom = crop_images(imgs)\n",
        "  features = find_features(cropped_imgs)\n",
        "\n",
        "  overlay_deltas: list[tuple[int, int]] = [(0,0)]*len(imgs)\n",
        "\n",
        "  for j in range(1, len(features)):\n",
        "    for i in reversed(range(0, j)):\n",
        "      deltas = match_features(features[i], features[j])\n",
        "      scores = [overlay_score(cropped_imgs[i], cropped_imgs[j], delta[::-1]) for delta in deltas]\n",
        "\n",
        "      if min(scores, default=1) > ALIGNMENT_SCORE_THRESHOLD:\n",
        "        print()\n",
        "        for score, delta in zip(scores, deltas):\n",
        "          print(f\"img{i} and img{j} with delta {delta} = {score}\")\n",
        "        print(f\"img{i} and img{j} DO NOT MATCH!!\")\n",
        "        print()\n",
        "        continue\n",
        "\n",
        "      k = np.argmin(scores)\n",
        "      print(f\"mathed img{i} and img{j} with delta {deltas[k]} = {scores[k]}\")\n",
        "      x,y = overlay_deltas[i]\n",
        "      dx,dy = deltas[k][::-1]\n",
        "      overlay_deltas[j] = (x+dx, y+dy)\n",
        "      break\n",
        "    else:\n",
        "      print(f\"img{j} does not know where to go :(\")\n",
        "      _, bottomx = find_top_bottom(cropped_imgs, overlay_deltas)\n",
        "      _,y = overlay_deltas[j-1]\n",
        "      overlay_deltas[j] = (bottomx+10, y)\n",
        "\n",
        "  topx, bottomx = find_top_bottom(cropped_imgs, overlay_deltas)\n",
        "  overlay_deltas.insert(0, (topx-top.shape[0], 0))\n",
        "  overlay_deltas.append((bottomx, overlay_deltas[-1][1]))\n",
        "  print(overlay_deltas)\n",
        "  res = overlay_images([top] + cropped_imgs + [bottom], overlay_deltas)\n",
        "  if outpath is None:\n",
        "    cv2_imshow(res)\n",
        "  else:\n",
        "    cv2.imwrite(outpath, res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew28TtgCiH0C"
      },
      "source": [
        "### Панорама"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zawcnrEQiCrO",
        "outputId": "79069cd4-21bd-45b5-adf7-de13a5d8b6f8"
      },
      "outputs": [],
      "source": [
        "ALIGNMENT_SCORE_THRESHOLD = 0.3\n",
        "main([f\"test cases/carmel_{i}.png\" for i in range(1, 5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeaKUJoxjLWp"
      },
      "source": [
        "Работает ожидаемо плохо, но оно нам и не надо)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27bZoSarjSB5"
      },
      "source": [
        "### Чат (на этот раз без обрезаний)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5RmVRHiXiUux",
        "outputId": "429c5381-a91f-497f-81ab-cb2c6380deed"
      },
      "outputs": [],
      "source": [
        "ALIGNMENT_SCORE_THRESHOLD = 0.015\n",
        "main([f\"test cases/chat_{i}.jpg\" for i in range(1, 4)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uruwy-LukbrL"
      },
      "source": [
        "### Аниме"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OQpIWXaPjb5E",
        "outputId": "a6883ed1-f857-4312-efa7-f71be88a89af"
      },
      "outputs": [],
      "source": [
        "ALIGNMENT_SCORE_THRESHOLD = 0.015\n",
        "REFERENCE_HEADER_IMAGE = -1\n",
        "main([f\"test cases/animepan_{i}.jpg\" for i in range(1, 6)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvIgn3txlHkP"
      },
      "source": [
        "Работает, но видны граници между разными скринами, потому что я просто копирую их в результат без всякого сглаживания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-2J7QRIlWYq"
      },
      "source": [
        "### Файлы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ppNCYC8qkm7l",
        "outputId": "dca42d4c-b561-4c1d-e803-74456e053280"
      },
      "outputs": [],
      "source": [
        "main([f\"test cases/files_{i}.png\" for i in range(1, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t5ouPutlmMC"
      },
      "source": [
        "Файлы удачно склеились, ура! Но если бы мы использовали другой feature detecter, кроме SIFT, то он бы не нашёл достаточно фич. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxLpUHKVl0Jb"
      },
      "source": [
        "### Код самого себя (ура рекурсия)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9U7iNKDaleV2",
        "outputId": "ccf6c6e8-97b0-440c-dee0-5f54276dc56c"
      },
      "outputs": [],
      "source": [
        "ALIGNMENT_SCORE_THRESHOLD = 0.015\n",
        "GREEDY_HEADER = True\n",
        "REFERENCE_HEADER_IMAGE = 3  # Иногда мой детектер повторейний плохо работает, и ему надо чучуть помочь(\n",
        "display_images(GIT_REPO_RAW+\"selfref_0{}.png\", 3)\n",
        "main([f\"test cases/selfref_{i:02}.png\" for i in range(1, 14)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwmG6mN9nysL"
      },
      "source": [
        "И это ровно тот результат, которого я хотел! Только почему-то в колабе мой код работает раза в три медленее, чем у меня дома внутри виртуалки WSL2..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzlM9HgOoH59"
      },
      "source": [
        "### Clip art"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gxBK56-3mPeh",
        "outputId": "b2be7cce-2f59-4852-dde3-dfd5c97fee4e"
      },
      "outputs": [],
      "source": [
        "GREEDY_HEADER = False\n",
        "REFERENCE_HEADER_IMAGE = 0\n",
        "main([f\"test cases/undraw_{i}.png\" for i in range(9)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqXNGCpdo7wy"
      },
      "source": [
        "Это конечно не то, что мы хотели, но всё таки лучше дефолтного стичера. Тут попрежнему нехватает фич... Наеврно, если бы мы реально хотели решить эту проблему, надо будет писать свой feature detector, который бы мог разпознавать такие плавные кривые."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oq9gqiEoPsR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
